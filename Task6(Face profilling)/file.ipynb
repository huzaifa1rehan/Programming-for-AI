{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 183.0ms\n",
      "Speed: 8.4ms preprocess, 183.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 175.2ms\n",
      "Speed: 4.3ms preprocess, 175.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.2ms\n",
      "Speed: 3.1ms preprocess, 135.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.6ms\n",
      "Speed: 4.7ms preprocess, 147.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.0ms\n",
      "Speed: 2.7ms preprocess, 150.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.3ms\n",
      "Speed: 4.3ms preprocess, 143.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.6ms\n",
      "Speed: 3.9ms preprocess, 150.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.7ms\n",
      "Speed: 4.5ms preprocess, 157.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 170.1ms\n",
      "Speed: 7.5ms preprocess, 170.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.1ms\n",
      "Speed: 3.4ms preprocess, 146.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 202.4ms\n",
      "Speed: 3.6ms preprocess, 202.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.5ms\n",
      "Speed: 5.2ms preprocess, 151.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.3ms\n",
      "Speed: 2.7ms preprocess, 153.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 166.4ms\n",
      "Speed: 5.2ms preprocess, 166.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.2ms\n",
      "Speed: 5.4ms preprocess, 147.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 130.3ms\n",
      "Speed: 3.9ms preprocess, 130.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.0ms\n",
      "Speed: 2.5ms preprocess, 131.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.7ms\n",
      "Speed: 3.5ms preprocess, 149.7ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.9ms\n",
      "Speed: 4.6ms preprocess, 132.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 137.9ms\n",
      "Speed: 4.7ms preprocess, 137.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.7ms\n",
      "Speed: 4.0ms preprocess, 132.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.9ms\n",
      "Speed: 5.1ms preprocess, 129.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.7ms\n",
      "Speed: 2.5ms preprocess, 154.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 140.1ms\n",
      "Speed: 2.8ms preprocess, 140.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.7ms\n",
      "Speed: 2.5ms preprocess, 133.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 138.9ms\n",
      "Speed: 3.7ms preprocess, 138.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 134.4ms\n",
      "Speed: 5.4ms preprocess, 134.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.8ms\n",
      "Speed: 4.2ms preprocess, 151.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.8ms\n",
      "Speed: 3.1ms preprocess, 126.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.1ms\n",
      "Speed: 4.7ms preprocess, 131.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.0ms\n",
      "Speed: 3.7ms preprocess, 131.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 124.6ms\n",
      "Speed: 2.5ms preprocess, 124.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.4ms\n",
      "Speed: 4.5ms preprocess, 135.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.4ms\n",
      "Speed: 3.5ms preprocess, 125.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.7ms\n",
      "Speed: 2.9ms preprocess, 129.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 140.2ms\n",
      "Speed: 2.9ms preprocess, 140.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 124.0ms\n",
      "Speed: 2.6ms preprocess, 124.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.9ms\n",
      "Speed: 5.8ms preprocess, 133.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.3ms\n",
      "Speed: 4.4ms preprocess, 131.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.2ms\n",
      "Speed: 3.5ms preprocess, 133.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.0ms\n",
      "Speed: 3.7ms preprocess, 144.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 127.3ms\n",
      "Speed: 6.0ms preprocess, 127.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.0ms\n",
      "Speed: 3.2ms preprocess, 128.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 156.5ms\n",
      "Speed: 2.8ms preprocess, 156.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.4ms\n",
      "Speed: 4.5ms preprocess, 132.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.0ms\n",
      "Speed: 5.1ms preprocess, 143.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.6ms\n",
      "Speed: 2.9ms preprocess, 128.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 137.5ms\n",
      "Speed: 3.8ms preprocess, 137.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 136.8ms\n",
      "Speed: 2.7ms preprocess, 136.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.3ms\n",
      "Speed: 4.9ms preprocess, 128.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 136.9ms\n",
      "Speed: 4.1ms preprocess, 136.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.0ms\n",
      "Speed: 2.5ms preprocess, 133.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "yolo_model = YOLO(\"yolov8n.pt\", verbose=False)\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "def align_face(face_image, landmarks):\n",
    "    left_eye = np.array([landmarks.landmark[468].x * face_image.shape[1], landmarks.landmark[468].y * face_image.shape[0]])\n",
    "    right_eye = np.array([landmarks.landmark[473].x * face_image.shape[1], landmarks.landmark[473].y * face_image.shape[0]])\n",
    "\n",
    "    dY = right_eye[1] - left_eye[1]\n",
    "    dX = right_eye[0] - left_eye[0]\n",
    "    angle = np.degrees(np.arctan2(dY, dX))\n",
    "\n",
    "    center = (face_image.shape[1] // 2, face_image.shape[0] // 2)\n",
    "    rot_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "    aligned_face = cv2.warpAffine(face_image, rot_matrix, (face_image.shape[1], face_image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return aligned_face\n",
    "\n",
    "def save_results(image, measurements):\n",
    "    with open(\"face_measurements.txt\", \"w\") as f:\n",
    "        for key, value in measurements.items():\n",
    "            f.write(f\"{key}: {value:.2f} mm\\n\")\n",
    "    print(\"Results saved: captured_face.jpg and face_measurements.txt\")\n",
    "\n",
    "reference_object_width_pixels = 100\n",
    "reference_object_width_mm = 25\n",
    "pixel_to_mm_ratio = reference_object_width_mm / reference_object_width_pixels\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_captured = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = yolo_model(rgb_frame)\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "            face_image = rgb_frame[y1:y2, x1:x2]\n",
    "            face_results = face_mesh.process(face_image)\n",
    "\n",
    "            if face_results.multi_face_landmarks:\n",
    "                for face_landmarks in face_results.multi_face_landmarks:\n",
    "                    aligned_face = align_face(face_image, face_landmarks)\n",
    "\n",
    "                    left_eye = np.array([face_landmarks.landmark[468].x * (x2 - x1), face_landmarks.landmark[468].y * (y2 - y1)])\n",
    "                    right_eye = np.array([face_landmarks.landmark[473].x * (x2 - x1), face_landmarks.landmark[473].y * (y2 - y1)])\n",
    "                    nose_tip = np.array([face_landmarks.landmark[4].x * (x2 - x1), face_landmarks.landmark[4].y * (y2 - y1)])\n",
    "                    chin = np.array([face_landmarks.landmark[152].x * (x2 - x1), face_landmarks.landmark[152].y * (y2 - y1)])\n",
    "\n",
    "                    eye_distance = calculate_distance(left_eye, right_eye) * pixel_to_mm_ratio\n",
    "                    nose_width = calculate_distance(nose_tip - np.array([20, 0]), nose_tip + np.array([20, 0])) * pixel_to_mm_ratio\n",
    "                    face_length = calculate_distance(nose_tip, chin) * pixel_to_mm_ratio\n",
    "\n",
    "                    mp_drawing = mp.solutions.drawing_utils\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=aligned_face,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1)\n",
    "                    )\n",
    "\n",
    "                    cv2.putText(aligned_face, f\"Eye Distance: {eye_distance:.2f} mm\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    cv2.putText(aligned_face, f\"Nose Width: {nose_width:.2f} mm\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    cv2.putText(aligned_face, f\"Face Length: {face_length:.2f} mm\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "                    output_frame = cv2.cvtColor(aligned_face, cv2.COLOR_RGB2BGR)\n",
    "                    cv2.imshow(\"Face Measurement System\", output_frame)\n",
    "\n",
    "                    if cv2.waitKey(1) & 0xFF == ord('s') and not face_captured:\n",
    "                        measurements = {\n",
    "                            \"Eye Distance\": eye_distance,\n",
    "                            \"Nose Width\": nose_width,\n",
    "                            \"Face Length\": face_length\n",
    "                        }\n",
    "                        save_results(aligned_face, measurements)\n",
    "                        face_captured = True\n",
    "\n",
    "    if cv2.waitKey(1) != -1: \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
